{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Section 1:  Recommendation Based on Popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6040 entries, u1 to u999\n",
      "Columns: 3706 entries, m1 to m999\n",
      "dtypes: float64(3706)\n",
      "memory usage: 170.8+ MB\n",
      "Title: American Beauty (1999) (Rating: 4.32, Count: 3428)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 45\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m top_10_with_titles\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTitle: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTitle\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (Rating: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverageRating\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Count: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRatingCount\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 45\u001b[0m     display(\u001b[43mImage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./MovieImages/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMovieID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.jpg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "movies_cols = ['MovieID', 'Title', 'Genres']\n",
    "movies = pd.read_csv('ml-1m/movies.dat', sep='::', names=movies_cols, encoding='latin-1', engine='python')\n",
    "\n",
    "rating_matrix = pd.read_csv('Rmat.csv')\n",
    "\n",
    "rating_matrix.head(), rating_matrix.info()\n",
    "\n",
    "rating_stats = {\n",
    "    \"num_users\": rating_matrix.shape[0],\n",
    "    \"num_movies\": rating_matrix.shape[1],\n",
    "    \"num_ratings\": rating_matrix.count().sum(),\n",
    "    \"rating_density\": rating_matrix.count().sum() / (rating_matrix.shape[0] * rating_matrix.shape[1])\n",
    "}\n",
    "\n",
    "\n",
    "ratings_filled = rating_matrix.fillna(0)\n",
    "\n",
    "movie_rating_counts = ratings_filled.astype(bool).sum(axis=0)\n",
    "\n",
    "movie_avg_ratings = rating_matrix.mean(axis=0, skipna=True)\n",
    "\n",
    "popularity_df = pd.DataFrame({\n",
    "    \"MovieID\": rating_matrix.columns,\n",
    "    \"RatingCount\": movie_rating_counts,\n",
    "    \"AverageRating\": movie_avg_ratings\n",
    "}).sort_values(by=[\"RatingCount\", \"AverageRating\"], ascending=[False, False])\n",
    "\n",
    "\n",
    "popularity_df['MovieID'] = popularity_df['MovieID'].str.lstrip('m')\n",
    "popularity_df['MovieID'] = popularity_df['MovieID'].astype(str)\n",
    "movies['MovieID'] = movies['MovieID'].astype(str)\n",
    "top_10_popular_movies = popularity_df.head(10)\n",
    "\n",
    "\n",
    "\n",
    "top_10_popular_movies = popularity_df.head(10)\n",
    "top_10_with_titles = pd.merge(top_10_popular_movies, movies, on='MovieID', how='left')\n",
    "\n",
    "for _, row in top_10_with_titles.iterrows():\n",
    "    print(f\"Title: {row['Title']} (Rating: {row['AverageRating']:.2f}, Count: {row['RatingCount']})\")\n",
    "    display(Image(filename=f\"./MovieImages/{row['MovieID']}.jpg\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def normalize_ratings(R):\n",
    "    row_means = R.mean(axis=1, skipna=True)\n",
    "    R_normalized = R.sub(row_means, axis=0)\n",
    "    return R_normalized, row_means\n",
    "\n",
    "\n",
    "def compute_cosine_similarity(R_normalized):\n",
    "    R_normalized = np.array(R_normalized)\n",
    "\n",
    "    num_movies = R_normalized.shape[1]\n",
    "    S = np.full((num_movies, num_movies), np.nan)  \n",
    "\n",
    "    for i in range(num_movies):\n",
    "        for j in range(i + 1, num_movies):  \n",
    "\n",
    "            common_users = ~np.isnan(R_normalized[:, i]) & ~np.isnan(R_normalized[:, j])\n",
    "            \n",
    "            if np.sum(common_users) > 2:  \n",
    "                R_i = R_normalized[common_users, i]\n",
    "                R_j = R_normalized[common_users, j]\n",
    "                numerator = np.sum(R_i * R_j)\n",
    "                denominator = np.sqrt(np.sum(R_i**2)) * np.sqrt(np.sum(R_j**2))\n",
    "                \n",
    "                if denominator > 0:\n",
    "                    similarity = 0.5 + 0.5 * (numerator / denominator)  \n",
    "                    S[i, j] = similarity\n",
    "                    S[j, i] = similarity  \n",
    "                    \n",
    "    return S\n",
    "\n",
    "\n",
    "\n",
    "def adjust_similarity_matrix(S, top_k=30):\n",
    "    S_copy = S.copy()\n",
    "\n",
    "    for i, row in S_copy.iterrows():\n",
    "        top_indices = row.dropna().nlargest(top_k).index\n",
    "        S_copy.loc[i, ~S_copy.columns.isin(top_indices)] = np.nan\n",
    "\n",
    "    return S_copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = pd.read_csv('Rmat.csv')  \n",
    "R_normalized, row_means = normalize_ratings(R)  # Normalize ratings\n",
    "#print(R_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = compute_cosine_similarity(R_normalized) \n",
    "S_df = pd.DataFrame(S, columns=R_normalized.columns, index=R_normalized.columns)\n",
    "#print(S_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             m1       m10      m100  m1510      m260  m3212\n",
      "m1          NaN 0.5121055 0.3919999    NaN 0.7411482    NaN\n",
      "m10   0.5121055       NaN 0.5474583    NaN 0.5343338    NaN\n",
      "m100  0.3919999 0.5474583       NaN    NaN 0.3296943    NaN\n",
      "m1510       NaN       NaN       NaN    NaN       NaN    NaN\n",
      "m260  0.7411482 0.5343338 0.3296943    NaN       NaN    NaN\n",
      "m3212       NaN       NaN       NaN    NaN       NaN    NaN\n"
     ]
    }
   ],
   "source": [
    "\n",
    "movie_ids = ['m1', 'm10', 'm100', 'm1510', 'm260', 'm3212']\n",
    "\n",
    "similarity_dict = {movie: [None] * len(movie_ids) for movie in movie_ids}\n",
    "\n",
    "for i in range(len(movie_ids)):\n",
    "    for j in range(i+1, len(movie_ids)): \n",
    "        movie_i = movie_ids[i]\n",
    "        movie_j = movie_ids[j]\n",
    "        \n",
    "        similarity_value = S_df.loc[movie_i, movie_j]\n",
    "        \n",
    "     \n",
    "        similarity_dict[movie_i][j] = similarity_value\n",
    "        similarity_dict[movie_j][i] = similarity_value  \n",
    "\n",
    "similarity_matrix = pd.DataFrame(similarity_dict, index=movie_ids, columns=movie_ids)\n",
    "\n",
    "similarity_matrix_rounded = similarity_matrix.round(7)\n",
    "\n",
    "pd.set_option('display.float_format', '{:,.7f}'.format)\n",
    "\n",
    "# Display the similarity matrix\n",
    "print(similarity_matrix_rounded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_adjusted = adjust_similarity_matrix(S_df) \n",
    "# print(S_adjusted.head(10))\n",
    "S_adjusted.to_csv('adjusted_similarity_matrix.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Recommendations for user1181: MovieID  PredictedRating\n",
      "  m3732        5.0000000\n",
      "   m749        4.5265592\n",
      "  m3899        4.5260660\n",
      "  m1039        4.0000000\n",
      "  m1235        4.0000000\n",
      "  m1253        4.0000000\n",
      "  m1734        4.0000000\n",
      "  m1914        4.0000000\n",
      "  m2082        4.0000000\n",
      "  m2361        4.0000000\n",
      "Top 10 Recommendations for hypothetical user: MovieID  PredictedRating\n",
      "  m1468        5.0000000\n",
      "  m1518        5.0000000\n",
      "  m2643        5.0000000\n",
      "  m2688        5.0000000\n",
      "  m2977        5.0000000\n",
      "   m435        5.0000000\n",
      "   m436        5.0000000\n",
      "  m1003        5.0000000\n",
      "   m117        5.0000000\n",
      "  m1243        5.0000000\n"
     ]
    }
   ],
   "source": [
    "def myIBCF(newuser, similarity_matrix, rating_matrix, popularity_df, top_k=10):\n",
    "    newuser = np.array(newuser)\n",
    "    \n",
    "    if similarity_matrix.shape[0] != rating_matrix.shape[1]:\n",
    "        raise ValueError(\"Similarity matrix and rating matrix dimensions do not align.\")\n",
    "    \n",
    "    predictions = np.full(len(newuser), np.nan)\n",
    "    \n",
    "\n",
    "    for i in range(len(newuser)):\n",
    "        if np.isnan(newuser[i]):\n",
    "            similarities = similarity_matrix.iloc[i, :]\n",
    "            rated_movies_indices = np.where(~np.isnan(newuser))[0]\n",
    "            valid_similarities = similarities.iloc[rated_movies_indices]\n",
    "            rated_movie_ratings = newuser[rated_movies_indices]\n",
    "            \n",
    "            non_na_mask = ~valid_similarities.isna()\n",
    "            valid_similarities = valid_similarities[non_na_mask]\n",
    "            rated_movie_ratings = rated_movie_ratings[non_na_mask]\n",
    "            \n",
    "            weighted_sum = np.sum(valid_similarities * rated_movie_ratings)\n",
    "            similarity_sum = np.sum(np.abs(valid_similarities))\n",
    "#             print(f\"Similarities for movie {i}: {valid_similarities}\")\n",
    "#             print(f\"Weighted sum for movie {i}: {weighted_sum}\")\n",
    "\n",
    "            if similarity_sum > 0:\n",
    "                predictions[i] = weighted_sum / similarity_sum\n",
    "                #print(f\"Movie {i}: Weighted Sum = {weighted_sum}, Similarity Sum = {similarity_sum}, Predicted Rating = {predictions[i]}\")\n",
    "        \n",
    "    movie_ids = rating_matrix.columns\n",
    "    prediction_df = pd.DataFrame({\n",
    "        \"MovieID\": movie_ids,\n",
    "        \"PredictedRating\": predictions\n",
    "    })\n",
    "    \n",
    "    already_rated_movies = set(np.where(~np.isnan(newuser))[0])\n",
    "    prediction_df = prediction_df[~prediction_df.index.isin(already_rated_movies)]\n",
    "    prediction_df = prediction_df.sort_values(\n",
    "        by=[\"PredictedRating\", \"MovieID\"],\n",
    "        ascending=[False, True]\n",
    ")\n",
    "\n",
    "    recommended_movies = prediction_df.head(top_k).dropna(subset=[\"PredictedRating\"])\n",
    "    \n",
    "    if len(recommended_movies) < top_k:\n",
    "        remaining_movies = [\n",
    "            movie for movie in popularity_df[\"MovieID\"]\n",
    "            if movie not in already_rated_movies\n",
    "        ]\n",
    "        remaining_df = pd.DataFrame({\n",
    "            \"MovieID\": remaining_movies[:top_k - len(recommended_movies)],\n",
    "            \"PredictedRating\": [None] * (top_k - len(recommended_movies))\n",
    "        })\n",
    "        recommended_movies = pd.concat([recommended_movies, remaining_df])\n",
    "\n",
    "    return recommended_movies\n",
    "\n",
    "\n",
    "\n",
    "def save_popularity_ranking(rating_matrix, output_file=\"popularity_ranking.csv\"):\n",
    "\n",
    "    movie_popularity = rating_matrix.notna().sum(axis=0)\n",
    "    popularity_ranking = movie_popularity.sort_values(ascending=False).index.tolist()\n",
    "    pd.DataFrame({\"MovieID\": popularity_ranking}).to_csv(output_file, index=False)\n",
    "    return popularity_ranking\n",
    "\n",
    "\n",
    "popularity_ranking = save_popularity_ranking(rating_matrix)\n",
    "\n",
    "\n",
    "u1181_ratings = rating_matrix.loc['u1181'].values\n",
    "\n",
    "\n",
    "hypothetical_user = np.full(R.shape[1], np.nan)\n",
    "hypothetical_user[1613 - 1] = 5  \n",
    "hypothetical_user[1755 - 1] = 4  \n",
    "\n",
    "recommendations = myIBCF(u1181_ratings, S_adjusted, R, popularity_ranking)\n",
    "print(\"Top 10 Recommendations for user1181:\", recommendations.to_string(index=False))\n",
    "recommendations = myIBCF(hypothetical_user, S_adjusted, R, popularity_ranking)\n",
    "print(\"Top 10 Recommendations for hypothetical user:\", recommendations.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
